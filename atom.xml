<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sugan&#39;s blog</title>
  
  <subtitle>Keep on thinking, and learn how people think.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://sugan.fun/"/>
  <updated>2018-08-30T04:21:47.000Z</updated>
  <id>https://sugan.fun/</id>
  
  <author>
    <name>sugan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>HBase二级索引方案</title>
    <link href="https://sugan.fun/2018/08/29/hbase-secondary-index/"/>
    <id>https://sugan.fun/2018/08/29/hbase-secondary-index/</id>
    <published>2018-08-29T06:54:00.000Z</published>
    <updated>2018-08-30T04:21:47.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="HBase简介"><a href="#HBase简介" class="headerlink" title="HBase简介"></a>HBase简介</h2><p>HBase是一个构建在HDFS之上，用于海量数据存储分布式列存储系统。<br>参见下图，由于在HBase中：</p><ul><li>表的每行都是按照RowKey的字典序排序存储</li><li>表的数据是按照RowKey区间进行分割存储成多个region</li></ul><p>所以HBase主要适用下面这两种常见场景：</p><ul><li>适用于基于rowkey的单行数据快速随机读写</li><li>适合基于rowkey前缀的范围扫描</li></ul><a id="more"></a><p><img src="/images/2018/08/hbase-secondary-index/hbase-arch.png" alt="hbase-arch"></p><p><img src="/images/2018/08/hbase-secondary-index/hbase-region-splits.png" alt="hbase-region-splits"></p><h2 id="为什么需要HBase二级索引"><a href="#为什么需要HBase二级索引" class="headerlink" title="为什么需要HBase二级索引"></a>为什么需要HBase二级索引</h2><p>HBase里面只有rowkey作为一级索引， 如果要对库里的非rowkey字段进行数据检索和查询， 往往要通过MapReduce/Spark等分布式计算框架进行， 硬件资源消耗和时间延迟都会比较高。<br>为了HBase的数据查询更高效、适应更多的场景， 诸如使用非rowkey字段检索也能做到秒级响应， 或者支持各个字段进行模糊查询和多字段组合查询等， 因此需要在HBase上面构建二级索引， 以满足现实中更复杂多样的业务需求。</p><h2 id="HBase二级索引方案"><a href="#HBase二级索引方案" class="headerlink" title="HBase二级索引方案"></a>HBase二级索引方案</h2><p>接下来介绍下主流的几种HBase二级索引方案：</p><h3 id="基于Coprocessor方案"><a href="#基于Coprocessor方案" class="headerlink" title="基于Coprocessor方案"></a>基于Coprocessor方案</h3><h4 id="官方特性"><a href="#官方特性" class="headerlink" title="官方特性"></a>官方特性</h4><p>其实从0.94版本开始，HBase官方文档已经提出了hbase上面实现二级索引的一种路径：</p><ol><li>基于Coprocessor（0.92版本开始引入，达到支持类似传统RDBMS的触发器的行为）</li><li>开发自定义数据处理逻辑， 采用数据“双写”（dual-write）策略，在有数据写入同时同步到二级索引表</li></ol><h4 id="开源方案"><a href="#开源方案" class="headerlink" title="开源方案"></a>开源方案</h4><p>虽然官方一直也没提供内置的支持二级索引的工具， 不过业界也有些比较知名的基于Coprocessor的开源方案：</p><ul><li>华为的hindex ： 基于0.94版本，当年刚出来的时候比较火，但是版本较旧，看GitHub项目地址最近这几年就没更新过。</li><li>Apache Phoenix： 功能围绕着SQL on hbase，支持和兼容多个hbase版本， 二级索引只是其中一块功能。  二级索引的创建和管理直接有SQL语法支持，使用起来很简便， 该项目目前社区活跃度和版本更新迭代情况都比较好。</li></ul><p>Apache Phoenix在目前开源的方案中，是一个比较优的选择。主打SQL on HBase ， 基于SQL能完成HBase的CRUD操作，支持JDBC协议。   Apache Phoenix在Hadoop生态里面位置：<br><img src="/images/2018/08/hbase-secondary-index/phoenix-arch.png" alt="phoenix-arch"></p><p>Phoenix二级索引特点：</p><ul><li>Covered Indexes(覆盖索引) ：把关注的数据字段也附在索引表上，只需要通过索引表就能返回所要查询的数据（列）， 所以索引的列必须包含所需查询的列(SELECT的列和WHRER的列)。</li><li>Functional indexes(函数索引)： 索引不局限于列，支持任意的表达式来创建索引。</li><li>Global indexes(全局索引)：适用于读多写少场景。通过维护全局索引表，所有的更新和写操作都会引起索引的更新，写入性能受到影响。 在读数据时，Phoenix SQL会基于索引字段，执行快速查询。</li><li>Local indexes(本地索引)：适用于写多读少场景。 在数据写入时，索引数据和表数据都会存储在本地。在数据读取时， 由于无法预先确定region的位置，所以在读取数据时需要检查每个region（以找到索引数据），会带来一定性能（网络）开销</li></ul><p>其他的在网上也很多自己基于Coprocessor实现二级索引的文章，大体都是遵循类似的思路：  构建一份“索引”的映射关系，存储在另一张hbase表或者其他DB里面。</p><h4 id="方案优缺点："><a href="#方案优缺点：" class="headerlink" title="方案优缺点："></a>方案优缺点：</h4><ul><li>优点： 基于Coprocessor的方案，从开发设计的角度看， 把很多对二级索引管理的细节都封装在的Coprocessor具体实现类里面， 这些细节对外面读写的人是无感知的，简化了数据访问者的使用。  </li><li>缺点： 但是Coprocessor的方案入侵性比较强， 增加了在Regionserver内部需要运行和维护二级索引关系表的代码逻辑等，对Regionserver的性能会有一定影响。</li></ul><h3 id="非Coprocessor方案"><a href="#非Coprocessor方案" class="headerlink" title="非Coprocessor方案"></a>非Coprocessor方案</h3><p><br>选择不基于Coprocessor开发，自行在外部构建和维护索引关系也是另外一种方式。<br>常见的是采用底层基于Apache Lucene的Elasticsearch(下面简称ES)或Apache Solr ，来构建强大的索引能力、搜索能力，  例如支持模糊查询、全文检索、组合查询、排序等。</p><h4 id="Lily-HBase-Indexer"><a href="#Lily-HBase-Indexer" class="headerlink" title="Lily HBase Indexer"></a>Lily HBase Indexer</h4><p>Lily HBase Indexer(也简称 HBase Indexer)是国外的NGDATA公司开源的基于solr的索引构建工具， 特色是其基于HBase的备份机制，开发了一个叫SEP工具， 通过监控HBase 的WAL日志（Put/Delete操作），来触发对solr集群索引的异步更新， 基本对HBase无侵入性（但必须开启WAL ）， 流程图如下所示:</p><p><img src="/images/2018/08/hbase-secondary-index/lily-hbase-indexer.png" alt="lily-hbase-indexer"></p><h4 id="CDH-Search"><a href="#CDH-Search" class="headerlink" title="CDH Search"></a>CDH Search</h4><p>CDH Search是Hadoop发行商Cloudera公司开发的基于solr的HBase检索方案，部分<strong>集成了Lily HBase Indexer</strong>的功能。<br>下面是CDH search的核心组件交互图， 体现了在单次client端查询过程中， 核心的zookeeper和solr等的交互流程：<br><img src="/images/2018/08/hbase-secondary-index/cdh-search.png" alt="cdh-search"></p><p>CDH 支持构建索引方式:</p><ul><li>批量索引：<ul><li>使用 Spark ：CDH自带 spark 批量index工具</li><li>使用MapReduce ：集成Lily Indexer、自带MR index等工具</li></ul></li><li>近实时索引（增量场景）：<ul><li>使用 Flume 近实时（NRT）索引</li><li>集成Lily NRT Indexer</li></ul></li><li>基于Solr REST API自定义索引场景</li></ul><p>CDH Solr 索引查询流程示意图：<br>  <img src="/images/2018/08/hbase-secondary-index/cdh-index-query.png" alt="cdh-index-query"></p><h2 id="Datastory-二级索引方案介绍"><a href="#Datastory-二级索引方案介绍" class="headerlink" title="Datastory 二级索引方案介绍"></a>Datastory 二级索引方案介绍</h2><p>其实对于在外部自定义构建二级索引的方式， 有自己的大数据团队的公司一般都会针对自己的业务场景进行优化， 自行构建ES/Solr的搜索集群。 例如数说故事企业内部的百亿级数据全量库，就是基于ES构建海量索引和检索能力的案例。 主要优化点包括：</p><ul><li>对企业的索引集群面向的业务场景和模式定制，对通用数据模型进行抽象和平台化复用</li><li>需要针对多业务、多项目场景进行ES集群资源的合理划分和运维管理</li><li>查询需要针对多索引集群、跨集群查询进行优化</li><li>共用集群场景需要做好防护、监控、限流</li></ul><p>下面显示了数说基于ES做二级索引的两种构建流程， 包含：</p><ul><li>增量索引： 日常持续接入的数据源， 进行增量的索引更新</li><li>全量索引： 配套基于Spark/MR的批量索引创建/更新程序， 用于初次或重建已有HBase库表的索引</li></ul><p><img src="/images/2018/08/hbase-secondary-index/ds-all-db.png" alt="ds-all-db"></p><p>数据查询流程：</p><p><img src="/images/2018/08/hbase-secondary-index/ds-alldb-query.png" alt="ds-alldb-query"></p><p>Datastory在做全量库的过程中，还是有更多遇到的问题要解决，诸如数据一致性、大量小索引、多版本ES集群共存等， 会在后续进行更细致的介绍和分享。</p><!-- HBase作为在大数据技术生态系统中，几乎是不可或缺的一个存储数据库。 我们为了沿用HBase的海量存储特性，又让其能在不同业务场景中的满足我们的存储和查询需求， 需要对HBase构建二级索引。 通过对比了HBase官方、开源界和hadoop发行商、 大数据企业等的实施方案， --><p><hr><br>参考资料：</p><ul><li>HBase coprocessor: <a href="https://blogs.apache.org/hbase/entry/coprocessor_introduction" target="_blank" rel="noopener">https://blogs.apache.org/hbase/entry/coprocessor_introduction</a></li><li>Cloudera Search : <a href="https://www.cloudera.com/documentation/enterprise/5-14-x/topics/search.html" target="_blank" rel="noopener">https://www.cloudera.com/documentation/enterprise/5-14-x/topics/search.html</a></li><li>Apache Phoenix Secondary indexing: <a href="https://phoenix.apache.org/secondary_indexing.html" target="_blank" rel="noopener">https://phoenix.apache.org/secondary_indexing.html</a></li><li>NGDATA Lily HBase Indexer:  <ul><li><a href="https://github.com/NGDATA/hbase-indexer/wiki" target="_blank" rel="noopener">https://github.com/NGDATA/hbase-indexer/wiki</a></li><li><a href="https://www.ngdata.com/the-hbase-side-effect-processor-and-hbase-replication-monitoring/" target="_blank" rel="noopener">https://www.ngdata.com/the-hbase-side-effect-processor-and-hbase-replication-monitoring/</a></li></ul></li><li>深入理解HBase Indexer:<a href="https://blog.csdn.net/d6619309/article/details/51500368" target="_blank" rel="noopener">https://blog.csdn.net/d6619309/article/details/51500368</a></li><li>奇虎360 HBASE二级索引的设计与实践：  <a href="http://www.infoq.com/cn/presentations/qihoo360-hbase-two-stage-index-design-and-practice" target="_blank" rel="noopener">http://www.infoq.com/cn/presentations/qihoo360-hbase-two-stage-index-design-and-practice</a></li><li>华为hindex: <a href="https://github.com/Huawei-Hadoop/hindex" target="_blank" rel="noopener">https://github.com/Huawei-Hadoop/hindex</a></li><li>HBase应用场景、原理与基本架构: <a href="https://blog.csdn.net/qq_25371579/article/details/50894145" target="_blank" rel="noopener">https://blog.csdn.net/qq_25371579/article/details/50894145</a></li></ul><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;HBase简介&quot;&gt;&lt;a href=&quot;#HBase简介&quot; class=&quot;headerlink&quot; title=&quot;HBase简介&quot;&gt;&lt;/a&gt;HBase简介&lt;/h2&gt;&lt;p&gt;HBase是一个构建在HDFS之上，用于海量数据存储分布式列存储系统。&lt;br&gt;参见下图，由于在HBase中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;表的每行都是按照RowKey的字典序排序存储&lt;/li&gt;
&lt;li&gt;表的数据是按照RowKey区间进行分割存储成多个region&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以HBase主要适用下面这两种常见场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;适用于基于rowkey的单行数据快速随机读写&lt;/li&gt;
&lt;li&gt;适合基于rowkey前缀的范围扫描&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="技术" scheme="https://sugan.fun/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="hbase" scheme="https://sugan.fun/tags/hbase/"/>
    
      <category term="elasticsearch" scheme="https://sugan.fun/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>快速编译和修改特定class文件</title>
    <link href="https://sugan.fun/2018/08/06/quick-modify-jar-class/"/>
    <id>https://sugan.fun/2018/08/06/quick-modify-jar-class/</id>
    <published>2018-08-06T00:00:00.000Z</published>
    <updated>2018-08-09T16:46:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>在这里介绍一种快速编译和修改jar里面特定class文件的方法， 本质上是对javac 、java、zip命令的综合使用。 在某些场景，能极大地提高部署和上线效率， 但是仅适用于少数为了快速调试、对外上线的特定业务场景。但是， 在正规的工程管理里面，仍然需要按项目开发和代码管理规范来！</p><a id="more"></a><h2 id="前提知识"><a href="#前提知识" class="headerlink" title="前提知识"></a>前提知识</h2><ol><li>jar文件本质是采用zip压缩的zip包，允许使用 zip、unzip命令对jar文件进行操作， 具体自己看man手册</li><li>javac 只需要依赖的环境（依赖的环境变量、jar classpath ）完整即可正常对一个工程或java文件进行编译</li></ol><h2 id="需求场景"><a href="#需求场景" class="headerlink" title="需求场景"></a>需求场景</h2><p>以编译 HDP自带的 ranger unixusersync包为例，  ranger的源代码见：<a href="https://github.com/apache/ranger/tree/ranger-0.5.2-rc1/" target="_blank" rel="noopener">https://github.com/apache/ranger/tree/ranger-0.5.2-rc1/</a></p><p>需要修改下面这个文件， 改动里面的默认成参数，加快自动同步LDAP用户信息到ranger的频率（默认是1小时）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 路径：  org/apache/ranger/unixusersync/config/UserGroupSyncConfig.java</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> UGSYNC_SLEEP_TIME_IN_MILLIS_BETWEEN_CYCLE_LDAP_DEFAULT_VALUE = <span class="number">3600000L</span>;”</span><br></pre></td></tr></table></figure><h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h2><ol><li><p>在HDP安装目录，找到目标的ranger jar文件为： unixusersync-0.5.0.2.4.2.0-258.jar</p></li><li><p>拷贝jar重命名为 “unixusersync-0.5.0.2.4.2.0-258_sugan.jar” , 然后删除这个拷贝的jar里面指定的class文件</p></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@orochihdp1 dist]# cp unixusersync-0.5.0.2.4.2.0-258.jar  unixusersync-0.5.0.2.4.2.0-258_sugan.jar</span><br><span class="line">[root@orochihdp1 dist]# zip -d unixusersync-0.5.0.2.4.2.0-258_sugan.jar '/org/apache/ranger/unixusersync/config/UserGroupSyncConfig.class'</span><br></pre></td></tr></table></figure><ol start="3"><li>修改UserGroupSyncConfig.java 里面的值</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> UGSYNC_SLEEP_TIME_IN_MILLIS_BETWEEN_CYCLE_LDAP_DEFAULT_VALUE = <span class="number">60000L</span>;”      </span><br><span class="line"><span class="comment">//    改成 60000L，加快自动同步LDAP用户信息到ranger的频率，默认是1小时</span></span><br></pre></td></tr></table></figure><ol start="4"><li>编译：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 路径： root@orochihdp1:/usr/hdp/current/ranger-usersync/dist</span></span><br><span class="line"></span><br><span class="line">javac -Xlint:unchecked  -cp  /usr/hdp/current/ranger-usersync/lib/commons-cli-1.2.jar:/usr/hdp/current/ranger-usersync/lib/commons-codec-1.9.jar:/usr/hdp/current/ranger-usersync/lib/commons-collections-3.2.2.jar:/usr/hdp/current/ranger-usersync/lib/commons-configuration-1.10.jar:/usr/hdp/current/ranger-usersync/lib/commons-csv-1.0.jar:/usr/hdp/current/ranger-usersync/lib/commons-httpclient-3.1.jar:/usr/hdp/current/ranger-usersync/lib/commons-io-2.4.jar:/usr/hdp/current/ranger-usersync/lib/commons-lang-2.6.jar:/usr/hdp/current/ranger-usersync/lib/commons-logging-1.2.jar:/usr/hdp/current/ranger-usersync/lib/credentialbuilder-0.5.0.2.4.2.0-258.jar:/usr/hdp/current/ranger-usersync/lib/gson-2.2.4.jar:/usr/hdp/current/ranger-usersync/lib/guava-11.0.2.jar:/usr/hdp/current/ranger-usersync/lib/hadoop-auth-2.7.1.2.4.2.0-258.jar:/usr/hdp/current/ranger-usersync/lib/hadoop-common-2.7.1.2.4.2.0-258.jar:/usr/hdp/current/ranger-usersync/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/current/ranger-usersync/lib/jersey-bundle-1.17.1.jar:/usr/hdp/current/ranger-usersync/lib/log4j-1.2.17.jar:/usr/hdp/current/ranger-usersync/lib/ranger-util-0.5.0.2.4.2.0-258.jar:/usr/hdp/current/ranger-usersync/lib/slf4j-api-1.7.5.jar:unixauthservice-0.5.0.2.4.2.0-258.jar:**./unixusersync-0.5.0.2.4.2.0-258_sugan.jar **   ./org/apache/ranger/unixusersync/config/UserGroupSyncConfig.java</span><br></pre></td></tr></table></figure><ol start="5"><li>把编译出来的class文件打进jar</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zip -ru unixusersync-0.5.0.2.4.2.0-258_sugan.jar org/</span><br></pre></td></tr></table></figure><ol start="6"><li>把新的jar替换掉原来的jar（ 记得备份旧的）， 重启ranger</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面演示了这种方法， 体现了对Apache ranger这个组件的源码进行修改的便利性， 帮助我们省去了完整的ranger工程项目下载和本地搭建、  本地编译打包（这个过程还需要下载大量依赖的其他包， 而且编译时间也颇久），  节约了大量的时间。</p><p>借助这种猥琐姿势， 我们能在以下场景中提高我们的效率：</p><ul><li>开源组件源码修改和编译：  Hadoop、spark、yarn等等只要有对标版本的源码，  我们能快速修改某个jar的源代码和上线</li><li>线上平台调试： 对一些问题的调试，  可以临时写个java， 在线上环境（例如跳板机）编译和运行后做 debug</li><li>简单的逆向和破解场景： 这个方法同样适用，  前提是可反编译出目标代码并且目标的jar没做额外的加固和授权，  例如大部分第三方插件如 Jira a插件的破解</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在这里介绍一种快速编译和修改jar里面特定class文件的方法， 本质上是对javac 、java、zip命令的综合使用。 在某些场景，能极大地提高部署和上线效率， 但是仅适用于少数为了快速调试、对外上线的特定业务场景。但是， 在正规的工程管理里面，仍然需要按项目开发和代码管理规范来！&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://sugan.fun/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="java" scheme="https://sugan.fun/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>博客开篇</title>
    <link href="https://sugan.fun/2018/07/28/blog-start/"/>
    <id>https://sugan.fun/2018/07/28/blog-start/</id>
    <published>2018-07-28T00:00:00.000Z</published>
    <updated>2018-08-09T16:42:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>背景是之前7月初的时候心血来潮，感觉要开始写博客记录一些东西。在花了周末两天时间去折腾和搭建这个博客后， 就拖到7月底（期间都没碰过这个博客）， 现在才想起来要写个真正意义的博客的开篇文章。<br><a id="more"></a><br>对于这个博客的打算， 主要是以记录一些生活感悟、技术文章为主， 期望一个月能产出至少1篇吧。 简单讲下写博客的目标：</p><ul><li><p>对知识成体系的整理：对各个领域学习的知识进行整理。之前的做法是只要是能在网上找到的资料，就先摘录相关知识点放在印象笔记里面。 缺点是知识比较碎片化，而且没转换成自己的知识体系进行梳理。通过写博客，可以来push自己来整理和分享出来。</p></li><li><p>夯实自己的认知体系： 大部分会是对生活和工作经历的反思跟总结。 年轻的时候还没形成相对稳定的世界观和方法论，所以只是观察和思考为主，记下来估计也是流水账。现在年纪大了成熟了（咳咳），对比了前几年，觉得自己有自信能写出一些能体现“独立思考”跟对自己本时期有价值的感悟，写下来也好提醒自己不断去付诸实践。</p></li></ul><p>(未完待续… …)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;背景是之前7月初的时候心血来潮，感觉要开始写博客记录一些东西。在花了周末两天时间去折腾和搭建这个博客后， 就拖到7月底（期间都没碰过这个博客）， 现在才想起来要写个真正意义的博客的开篇文章。&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>基于hexo、atom打造本地写作环境和搭建blog</title>
    <link href="https://sugan.fun/2018/07/08/hexo-atom-blog/"/>
    <id>https://sugan.fun/2018/07/08/hexo-atom-blog/</id>
    <published>2018-07-08T08:23:00.000Z</published>
    <updated>2018-08-09T16:13:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>折腾了一整天的 atom、hexo相关插件安装配置，atom和hexo协作的一些小坑记录。在调试多个插件的配置和协作， 最后不得不改了插件的源码来解决图片路径问题，  最后打造了一个靠谱的本地md写作编辑器。</p><h2 id="编辑能力："><a href="#编辑能力：" class="headerlink" title="编辑能力："></a>编辑能力：</h2><blockquote><p>得益于<a href="https://shd101wyy.github.io/markdown-preview-enhanced/#/zh-cn/" target="_blank" rel="noopener">MPE扩展</a> （扩展语法、绘图， 编辑功能完爆马克飞象、Macdown这些，  还可以方便地在渲染后，借助浏览器或额外的插件， 在本地导出pdf。</p></blockquote><blockquote><p>得益于atom 的强大插件机制，  配出了顶部的markdown工具栏、右侧markdown增强渲染栏、 图片上传（支持截屏拷贝粘贴）和生成正确路径。</p></blockquote><a id="more"></a><h2 id="Blog部署："><a href="#Blog部署：" class="headerlink" title="Blog部署："></a>Blog部署：</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#本地预览：</span></span><br><span class="line">hexo clean &amp;&amp; hexo  g  &amp;&amp; hexo server -d</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#发布到线上:</span></span><br><span class="line">hexo d  <span class="comment"># hexo deploy, 集成了git</span></span><br></pre></td></tr></table></figure><h3 id="Hexo插件"><a href="#Hexo插件" class="headerlink" title="Hexo插件:"></a>Hexo插件:</h3><p><img src="/images/2018/07/hexo-atom-blog/hexo.png" style="height:400px"></p><!-- ![hexo](/images/2018/07/hexo-atom-blog/hexo.png) --><h3 id="apm插件："><a href="#apm插件：" class="headerlink" title="apm插件："></a>apm插件：</h3><p><img src="/images/2018/07/hexo-atom-blog/apm插件.png" style="height:150px"></p><h2 id="重要的配置说明："><a href="#重要的配置说明：" class="headerlink" title="重要的配置说明："></a>重要的配置说明：</h2><ol><li>atom项目根路径： hexo项目的的source目录</li><li>图片统一存储：在source目录下面创建一个images文件夹，作为全局的文件路径</li><li>markdown-writer，查看源代码，修改下面的地方，直接插入图片的时候， 路径就是完美的根路径， 跟部署到服务器上的路径也一致（下图）</li></ol><p><img src="/images/2018/07/hexo-atom-blog/md-writert-modify.png" style="height:200px"></p><h3 id="图片路径修正方法"><a href="#图片路径修正方法" class="headerlink" title="图片路径修正方法:"></a>图片路径修正方法:</h3><!-- ![p1](/images/2018/07/hexo-atom-blog/图片路径修正方法：.png) --><p><img src="/images/2018/07/hexo-atom-blog/图片路径修正方法：.png" style="height:150px"></p><h2 id="效果图"><a href="#效果图" class="headerlink" title="效果图:"></a>效果图:</h2><p><img src="/images/2018/07/hexo-atom-blog/总图.png" alt="总图"></p><p><img src="/images/2018/07/hexo-atom-blog/img-up.png" alt="本地文件上传"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;折腾了一整天的 atom、hexo相关插件安装配置，atom和hexo协作的一些小坑记录。在调试多个插件的配置和协作， 最后不得不改了插件的源码来解决图片路径问题，  最后打造了一个靠谱的本地md写作编辑器。&lt;/p&gt;
&lt;h2 id=&quot;编辑能力：&quot;&gt;&lt;a href=&quot;#编辑能力：&quot; class=&quot;headerlink&quot; title=&quot;编辑能力：&quot;&gt;&lt;/a&gt;编辑能力：&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;得益于&lt;a href=&quot;https://shd101wyy.github.io/markdown-preview-enhanced/#/zh-cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MPE扩展&lt;/a&gt; （扩展语法、绘图， 编辑功能完爆马克飞象、Macdown这些，  还可以方便地在渲染后，借助浏览器或额外的插件， 在本地导出pdf。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;得益于atom 的强大插件机制，  配出了顶部的markdown工具栏、右侧markdown增强渲染栏、 图片上传（支持截屏拷贝粘贴）和生成正确路径。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术" scheme="https://sugan.fun/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Hexo" scheme="https://sugan.fun/tags/Hexo/"/>
    
      <category term="Atom编辑器" scheme="https://sugan.fun/tags/Atom%E7%BC%96%E8%BE%91%E5%99%A8/"/>
    
  </entry>
  
</feed>
